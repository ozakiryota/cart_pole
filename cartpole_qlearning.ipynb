{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "cartpole_qlearning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMsKhckcXjw/BtYi4neJ2qk",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ozakiryota/cart_pole/blob/main/cartpole_qlearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzGR6DXx5hxW"
      },
      "source": [
        "# Cart-Pole\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NztiGF0Ld3ET"
      },
      "source": [
        "Install OpenAI Gym (https://gym.openai.com)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTnd9XdOQ0JA",
        "outputId": "82f6b475-bb9b-4ae8-f187-dbfa3f17d704"
      },
      "source": [
        "!pip install gym"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.19.5)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WatqsT0I5lxF"
      },
      "source": [
        "Install the packages for visualizing Gym"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo7Lrbp5Sqod",
        "outputId": "4ba5442b-62dc-4f02-ed9e-13ddecd5b7cb"
      },
      "source": [
        "!apt update\n",
        "!apt install xvfb\n",
        "!pip install pyvirtualdisplay"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [1 InRelease 14.2 kB/88.7\u001b[0m\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [1 InRelease 14.2 kB/88.7\u001b[0m\u001b[33m\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [1 InRelease 43.1 kB/88.7\u001b[0m\u001b[33m\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.142)\u001b[0m\u001b[33m\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.142)\u001b[0m\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\u001b[33m\r                                                                               \r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers]\u001b[0m\r                                                                         \rGet:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "\u001b[33m\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [4 InRelease 2,572 B/15.9 k\u001b[0m\r                                                                               \rHit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\u001b[33m\r0% [2 InRelease gpgv 3,626 B] [4 InRelease 2,572 B/15.9 kB 16%] [Waiting for he\u001b[0m\r                                                                               \rIgn:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\u001b[33m\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [4 InRelease 11.3 kB/15.9 k\u001b[0m\r                                                                               \rGet:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "\u001b[33m\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [4 InRelease 14.2 kB/15.9 k\u001b[0m\u001b[33m\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [4 InRelease 14.2 kB/15.9 k\u001b[0m\r                                                                               \rHit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "\u001b[33m\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [4 InRelease 14.2 kB/15.9 k\u001b[0m\r                                                                               \rGet:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [396 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,116 kB]\n",
            "Hit:15 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [24.7 kB]\n",
            "Hit:17 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Ign:19 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:19 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [741 kB]\n",
            "Get:20 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,756 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,181 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,546 kB]\n",
            "Get:23 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [899 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [426 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [31.6 kB]\n",
            "Fetched 11.4 MB in 3s (4,321 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "36 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  xvfb\n",
            "0 upgraded, 1 newly installed, 0 to remove and 36 not upgraded.\n",
            "Need to get 784 kB of archives.\n",
            "After this operation, 2,270 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.9 [784 kB]\n",
            "Fetched 784 kB in 1s (1,068 kB/s)\n",
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 160690 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.9_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading https://files.pythonhosted.org/packages/19/88/7a198a5ee3baa3d547f5a49574cd8c3913b216f5276b690b028f89ffb325/PyVirtualDisplay-2.1-py3-none-any.whl\n",
            "Collecting EasyProcess\n",
            "  Downloading https://files.pythonhosted.org/packages/48/3c/75573613641c90c6d094059ac28adb748560d99bd27ee6f80cce398f404e/EasyProcess-0.3-py2.py3-none-any.whl\n",
            "Installing collected packages: EasyProcess, pyvirtualdisplay\n",
            "Successfully installed EasyProcess-0.3 pyvirtualdisplay-2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cF70T7rbdLXM"
      },
      "source": [
        "## Random move"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9MoZlOvenEx"
      },
      "source": [
        "Import Gym"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDrypO0FZ9IG"
      },
      "source": [
        "import gym"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6r-cLs8ej61"
      },
      "source": [
        "Import the packages for visualizing Gym"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8zm1ycgaE8K"
      },
      "source": [
        "import base64\n",
        "import io\n",
        "from gym.wrappers import Monitor\n",
        "from IPython import display\n",
        "from pyvirtualdisplay import Display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaDIbpNE5dEJ"
      },
      "source": [
        "Move the cart-pole randomly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0fqxHSzwRByB",
        "outputId": "1b509829-9182-4dc3-bf40-e246e9c61a0f"
      },
      "source": [
        "virtual_display = Display()\n",
        "virtual_display.start()\n",
        "\n",
        "env = Monitor(gym.make('CartPole-v0'),'./videos/random_move/', force=True)\n",
        "print(\"env.observation_space.shape = \", env.observation_space.shape)\n",
        "print(\"env.action_space.n = \", env.action_space.n)\n",
        "\n",
        "obs = env.reset()\n",
        "\n",
        "for t in range(100):\n",
        "    obs, reward, is_done, info = env.step(env.action_space.sample())\n",
        "    print(\"obs = \", obs)\n",
        "    print(\"reward = \", reward)\n",
        "    print(\"info = \", info)\n",
        "\n",
        "    if is_done:\n",
        "        print(\"Episode finished after {} timesteps\".format(t+1))\n",
        "        env.reset()\n",
        "        break\n",
        "\n",
        "for frame in env.videos:\n",
        "    print(\"frame = \", frame)\n",
        "    video = io.open(frame[0], 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "\n",
        "    display.display(display.HTML(data=\"\"\"\n",
        "        <video alt=\"test\" controls>\n",
        "        <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "        </video>\n",
        "        \"\"\".format(encoded.decode('ascii'))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env.observation_space.shape =  (4,)\n",
            "env.action_space.n =  2\n",
            "obs =  [-0.04297903  0.20436805  0.03376966 -0.31653758]\n",
            "reward =  1.0\n",
            "info =  {}\n",
            "obs =  [-0.03889167  0.00878178  0.02743891 -0.01339904]\n",
            "reward =  1.0\n",
            "info =  {}\n",
            "obs =  [-0.03871603  0.20349969  0.02717093 -0.29729994]\n",
            "reward =  1.0\n",
            "info =  {}\n",
            "obs =  [-0.03464604  0.39822399  0.02122493 -0.58129131]\n",
            "reward =  1.0\n",
            "info =  {}\n",
            "obs =  [-0.02668156  0.59304221  0.0095991  -0.86721316]\n",
            "reward =  1.0\n",
            "info =  {}\n",
            "obs =  [-0.01482072  0.78803223 -0.00774516 -1.15686262]\n",
            "reward =  1.0\n",
            "info =  {}\n",
            "obs =  [ 0.00093993  0.5930121  -0.03088241 -0.86661825]\n",
            "reward =  1.0\n",
            "info =  {}\n",
            "obs =  [ 0.01280017  0.7885404  -0.04821478 -1.16884884]\n",
            "reward =  1.0\n",
            "info =  {}\n",
            "obs =  [ 0.02857098  0.59407766 -0.07159175 -0.89166337]\n",
            "reward =  1.0\n",
            "info =  {}\n",
            "obs =  [ 0.04045253  0.79009397 -0.08942502 -1.20596465]\n",
            "reward =  1.0\n",
            "info =  {}\n",
            "obs =  [ 0.05625441  0.5962341  -0.11354431 -0.9425927 ]\n",
            "reward =  1.0\n",
            "info =  {}\n",
            "obs =  [ 0.06817909  0.79268774 -0.13239617 -1.268686  ]\n",
            "reward =  1.0\n",
            "info =  {}\n",
            "obs =  [ 0.08403285  0.98922843 -0.15776989 -1.59972782]\n",
            "reward =  1.0\n",
            "info =  {}\n",
            "obs =  [ 0.10381742  1.18582829 -0.18976444 -1.93715715]\n",
            "reward =  1.0\n",
            "info =  {}\n",
            "obs =  [ 0.12753398  1.38240452 -0.22850759 -2.28218481]\n",
            "reward =  1.0\n",
            "info =  {}\n",
            "Episode finished after 15 timesteps\n",
            "frame =  ('/content/videos/random_move/openaigym.video.0.59.video000000.mp4', '/content/videos/random_move/openaigym.video.0.59.video000000.meta.json')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <video alt=\"test\" controls>\n",
              "        <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "        </video>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbBYRiI4Bgd-"
      },
      "source": [
        "## Q-learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgvZ1f4MccCJ"
      },
      "source": [
        "Import required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a3R-TE_gaS1"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Htu4VPF8cflL"
      },
      "source": [
        "Brain class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMFWoAE1RIRe"
      },
      "source": [
        "class Brain:\n",
        "    def __init__(self, num_states, list_state_range, list_state_reso, num_actions, gamma, r, lr):\n",
        "        self.num_states = num_states\n",
        "        self.list_state_range = list_state_range\n",
        "        self.list_state_reso = list_state_reso\n",
        "        self.num_actions = num_actions\n",
        "\n",
        "        self.eps = 1.0  # for epsilon greedy algorithm\n",
        "        self.gamma = gamma\n",
        "        self.r = r\n",
        "        self.lr = lr\n",
        "\n",
        "        self.q_table = np.random.rand(np.prod(list_state_reso), num_actions)\n",
        "\n",
        "    def bins(self, clip_min, clip_max, num):\n",
        "        return np.linspace(clip_min, clip_max, num + 1)[1:-1]\n",
        " \n",
        "    def getStateIndex(self, observation):\n",
        "        list_index = []\n",
        "        for i in range(self.num_states):\n",
        "            index = np.digitize(observation[i], bins=self.bins(self.list_state_range[i][0], self.list_state_range[i][1], self.list_state_reso[i]))\n",
        "            list_index.append(index)\n",
        "        return sum([index*int(np.prod(self.list_state_reso[:i])) for i, index in enumerate(list_index)])\n",
        "\n",
        "    def updateQtable(self, obs, action, reward, next_obs):\n",
        "        q = self.q_table[self.getStateIndex(obs), action]\n",
        "        next_q_max = np.max(self.q_table[self.getStateIndex(next_obs)])\n",
        "        self.q_table[self.getStateIndex(obs), action] = q + self.lr*(reward + self.gamma*next_q_max - q)\n",
        "\n",
        "    def getAction(self, obs, is_training):\n",
        "        if is_training and np.random.rand() < self.eps:\n",
        "            action = np.random.randint(self.num_actions)\n",
        "        else:\n",
        "            action = np.argmax(self.q_table[self.getStateIndex(obs)])\n",
        "        ## update eps\n",
        "        if is_training and self.eps > 0.1:\n",
        "            self.eps *= self.r\n",
        "        return action"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSn2nGYqzoqh"
      },
      "source": [
        "Agent class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnTqsw2uzsXP"
      },
      "source": [
        "class Agent:\n",
        "    def __init__(self, num_states, list_state_range, list_state_reso, num_actions, gamma, r, lr):\n",
        "        self.brain = Brain(num_states, list_state_range, list_state_reso, num_actions, gamma, r, lr)\n",
        " \n",
        "    def updateQtable(self, obs, action, reward, next_obs):\n",
        "        self.brain.updateQtable(obs, action, reward, next_obs)\n",
        " \n",
        "    def getAction(self, obs, is_training):\n",
        "        action = self.brain.getAction(obs, is_training)\n",
        "        return action"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzJjzN5VB-pQ"
      },
      "source": [
        "Environment class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuXmrqq7CBog"
      },
      "source": [
        "class Environment:\n",
        "    def __init__(self, num_episodes, max_step, gamma, r, lr):\n",
        "        ## parameters\n",
        "        self.num_episodes = num_episodes\n",
        "        self.max_step = max_step\n",
        "        ## environment\n",
        "        self.env = Monitor(gym.make('CartPole-v0'), './videos/q_learning/', force=True)\n",
        "        ## agent\n",
        "        num_states = self.env.observation_space.shape[0]    # position, velocity, angle, angular velocity\n",
        "        list_state_range = []\n",
        "        for i in range(num_states):\n",
        "            list_state_range.append([self.env.observation_space.low[i], self.env.observation_space.high[i]])\n",
        "        list_state_range[1] = [-3.0, 3.0]\n",
        "        list_state_range[3] = [-0.5, 0.5]\n",
        "        print(\"list_state_range = \", list_state_range)\n",
        "        list_state_reso = [4, 4, 6, 6]\n",
        "        num_actions = self.env.action_space.n\n",
        "\n",
        "        self.agent = Agent(num_states, list_state_range, list_state_reso, num_actions, gamma, r, lr)\n",
        " \n",
        "    def train(self):\n",
        "        num_completed_episodes = 0\n",
        "  \n",
        "        for episode in range(self.num_episodes):\n",
        "            obs = self.env.reset()\n",
        "            episode_reward = 0\n",
        " \n",
        "            for step in range(self.max_step):\n",
        "                ## get action\n",
        "                action = self.agent.getAction(obs, is_training=True)\n",
        "                ## observe next step\n",
        "                next_obs, _, is_done, _ = self.env.step(action)\n",
        "                ## get reward\n",
        "                if is_done:\n",
        "                    if step < max_step - 1:\n",
        "                        reward = -100\n",
        "                    else:\n",
        "                        reward = 1\n",
        "                        num_completed_episodes += 1\n",
        "                else:\n",
        "                    reward = 1\n",
        "                episode_reward += reward\n",
        "                ## update\n",
        "                self.agent.updateQtable(obs, action, reward, next_obs)\n",
        "                ## to next step\n",
        "                obs = next_obs\n",
        "\n",
        "                if is_done:\n",
        "                    print('{0} Episode: Finished after {1} time steps with reward {2}'.format(episode, step+1, episode_reward))\n",
        "                    break\n",
        "        print(\"num_completed_episodes = \", num_completed_episodes)\n",
        "\n",
        "    def evaluate(self):\n",
        "        obs = self.env.reset()\n",
        "        \n",
        "        for step in range(self.max_step):\n",
        "            ## get action\n",
        "            action = self.agent.getAction(obs, is_training=False)\n",
        "            ## observe next step\n",
        "            next_obs, _, is_done, _ = self.env.step(action)\n",
        "            ## to next step\n",
        "            obs = next_obs\n",
        "\n",
        "            if is_done:\n",
        "                print('Evaluation: Finished after {} time steps'.format(step+1))\n",
        "                break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDKojCejb2-A"
      },
      "source": [
        "Prepare showing videos of the restults"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvmszieobbrX"
      },
      "source": [
        "def show_video(env):\n",
        "    env.reset()\n",
        "    for frame in env.videos:\n",
        "        print(\"frame = \", frame)\n",
        "        video = io.open(frame[0], 'r+b').read()\n",
        "        encoded = base64.b64encode(video)\n",
        "\n",
        "        display.display(display.HTML(data=\"\"\"\n",
        "            <video alt=\"test\" controls>\n",
        "            <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "            </video>\n",
        "            \"\"\".format(encoded.decode('ascii')))\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "ZJqfOQ-tW0sA",
        "outputId": "4bb02e47-117b-4605-946a-dd2fd5c08490"
      },
      "source": [
        "## display\n",
        "virtual_display = Display()\n",
        "virtual_display.start()\n",
        "\n",
        "## parameters\n",
        "num_episodes = 500\n",
        "max_step = 200\n",
        "gamma = 0.9\n",
        "r = 0.99\n",
        "lr = 0.5\n",
        "\n",
        "## run\n",
        "cartpole_env = Environment(num_episodes, max_step, gamma, r, lr)\n",
        "cartpole_env.train()\n",
        "cartpole_env.evaluate()\n",
        "show_video(cartpole_env.env)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "list_state_range =  [[-4.8, 4.8], [-3.0, 3.0], [-0.41887903, 0.41887903], [-0.5, 0.5]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-72045afb6b3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m## run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mcartpole_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEnvironment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_episodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mcartpole_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mcartpole_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mshow_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcartpole_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-ba4aa7a36bcc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepisode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_episodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mepisode_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/wrappers/monitor.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/wrappers/monitor.py\u001b[0m in \u001b[0;36m_after_reset\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats_recorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_video_recorder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;31m# Bump *after* all reset activity has finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/wrappers/monitor.py\u001b[0m in \u001b[0;36mreset_video_recorder\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_video_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         )\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo_recorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_close_video_recorder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/wrappers/monitoring/video_recorder.py\u001b[0m in \u001b[0;36mcapture_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mrender_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ansi'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mansi_mode\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrender_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/envs/classic_control/cartpole.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassic_control\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mViewer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcartwidth\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcartwidth\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcartheight\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcartheight\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/envs/classic_control/rendering.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     raise ImportError('''\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyglet/gl/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mcompat_platform\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'darwin'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcocoa\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCocoaConfig\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mbase\u001b[0m  \u001b[0;31m# noqa: F821\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'base' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mESpPTF72xIr"
      },
      "source": [
        "## References\n",
        "- [Getting Started with Gym](https://gym.openai.com/docs/)\n",
        "- [【強化学習】OpenAI Gym を Google Colab上で描画する方法 (2020.6版)](https://qiita.com/ymd_h/items/c393797deb72e1779269)\n",
        "- [minnano_rl/section_2/01_simple_reinforcement_learning.ipynb](https://github.com/yukinaga/minnano_rl/blob/main/section_2/01_simple_reinforcement_learning.ipynb)\n",
        "- [第10回　CartPole課題をQ学習で制御する](https://book.mynavi.jp/manatee/detail/id=88997)"
      ]
    }
  ]
}